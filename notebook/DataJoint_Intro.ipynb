{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Welcome!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We appreciate you attending our DataJoint workshop. Let's learn how easy it is to create a DataJoint computational pipeline from scratch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please run the below but feel free to disregard it as it is just some environment specific setup configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd /home/notebooks/notebook\n",
    "import datajoint as dj\n",
    "dj.config['database.password'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "from requests import request\n",
    "import json\n",
    "from os import path\n",
    "from bs4 import BeautifulSoup\n",
    "# , mkdir\n",
    "# from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Workshop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Statement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- You are a journalist at UH covering sporting events around campus\n",
    "- There are various sports for both men and women atheletes\n",
    "- Each sporting event needs an article piece created on a specific date to promote and cover the event\n",
    "- An article should include both a headline and a thumbnail image\n",
    "- To promote both the article + sport, we should come up with an *attention-grabbing* flyer based on the article's thumbnail"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Connected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by importing `datajoint`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datajoint as dj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's open a connection to a database server instance or sometimes referred to as a pipeline. This step is not necessary but useful in debugging or simply verifying you have access."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dj.conn()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can list the databases you have access to by running:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dj.list_schemas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a Schema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's create a database or sometimes referred to as a database (in MySQL). This will be the primary namespace where we will  create our pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = dj.Schema('{user}_uh-showcase'.format(user=dj.config['database.user']))\n",
    "schema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Designing your Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the description of the problem, we can make the following assumptions:\n",
    "- A `Sport` has an attribute that determines whether it is for `men` or `women`\n",
    "- `Sport:NewsArticle` should have a `1:M` relationship\n",
    "- A `NewsArticle` has an attribute to specify when it was created\n",
    "- A `NewsArticle` has a `1:1` relationship both for its headline and thumbnail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@schema\n",
    "class Sport(dj.Manual):\n",
    "    definition = \"\"\"\n",
    "    sport_id  : int auto_increment\n",
    "    ---\n",
    "    name      : varchar(30)\n",
    "    sex=\"men\" : enum(\"women\", \"men\")\n",
    "    unique index(name, sex)\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@schema\n",
    "class NewsArticle(dj.Manual):\n",
    "    definition = \"\"\"\n",
    "    -> Sport\n",
    "    news_id   : int\n",
    "    ---\n",
    "    date=null : date\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To help visualize our pipeline, we can use the `dj.Diagram` function or `dj.Di` for short."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dj.Di(schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inserting Records"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's initialize some sports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sport.insert([\n",
    "    dict(name='swim', sex='women'),\n",
    "    dict(name='soc', sex='women')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also leverage the default value feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sport.insert([\n",
    "    dict(name='track'),\n",
    "    dict(name='football')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To confirm our inserts, we can preview the table's contents by running the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sport()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's add some entries into for our news articles that correspond to actual articles from UH's atheletics site: https://uhcougars.com/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NewsArticle.insert([\n",
    "    [2, 1, date(2019,11,5)],\n",
    "    [1, 1, date(2020,3,11)],\n",
    "    [3, 1, date(2020,3,4)],\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NewsArticle()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Querying"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose now that we wanted to perform some query to our pipeline to extract data from it. The following are a few examples how we can achieve this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Query1: `women` sports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sport & dict(sex='women')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Query2: `men` sports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = Sport & \"sex='men'\"\n",
    "q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Query3: Exclude any `men` sports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = Sport - dict(sex='men')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`q` here is actually just a query expression and unevaluated. Think of `q` as a query builder. The only reason why the queries were displaying values before is because we have been utilizing Jupyter's preview feature (which limits the results). It is important to understand that queries aren't expected to actually run until we can `fetch` on them (more on this later)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isinstance(q, dj.expression.QueryExpression)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can manually ask Jupyter to preview the query for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A great debugging tool as well is `make_sql` which allows us to see the assembled SQL query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q.make_sql()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Query4: Articles for `women`'s sports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NewsArticle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = Sport * NewsArticle & \"sex = 'women'\"\n",
    "q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To properly run and fetch your query, you'd call `fetch` on your query expression like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q.fetch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q.fetch(as_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q.fetch('name', 'sex', as_dict=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In DataJoint, computation is a native part of interacting with your data. Let's see how to leverage this within our pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, some important principles:\n",
    "- There are 2 different kinds of computed tables in DataJoint: `Imported` and `Computed`.\n",
    "- They operate essentially the same but we differentiate them purely on convention and how they are used.\n",
    "- `Imported` tables signal that there is external data being introduced to the pipeline.\n",
    "- `Computed` tables signal that there is new data being introduced but sourced from within the pipeline itself or sometimes referred to as upstream."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we can include this in our design by creating an `Imported` table that runs a web scraping computation to fetch the headline and thumbnail for the articles. Then, we can create a `Computed` table that runs a computation to modify our thumbnail to make it more interesting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start first with our `Imported` table. We can make the following assumptions:\n",
    "- The `Headline` table will store both the headline and the thumbnail for an article's given date.\n",
    "- A record in the `Headline` table should correspond to a single news article i.e. `1:1` relationship."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@schema\n",
    "class Headline(dj.Imported):\n",
    "    definition = \"\"\"\n",
    "    -> NewsArticle\n",
    "    ---\n",
    "    name : varchar(200)\n",
    "    image: longblob\n",
    "    \"\"\"\n",
    "\n",
    "    def make(self, key):    \n",
    "        sport_name, sport_sex = (Sport & key).fetch1('name', 'sex')\n",
    "        news_date = (NewsArticle & key).fetch1('date')\n",
    "        file_path = 'cached/{}_{}_{}.jpg'.format(sport_name, sport_sex, news_date)\n",
    "\n",
    "        if not path.exists(file_path):\n",
    "            base_url = \"https://uhcougars.com\"\n",
    "            headers = {\n",
    "                'User-Agent': \"DataJoint\"\n",
    "            }\n",
    "            querystring = {\n",
    "                \"index\":\"1\",\n",
    "                \"page_size\":\"200\",\n",
    "                \"sport\": sport_name if sport_sex != 'women' else sport_sex[0] + sport_name,\n",
    "                \"season\":\"0\"\n",
    "            }\n",
    "            response = request(\"GET\", base_url + \"/services/archives.ashx/stories\",\n",
    "                               headers=headers, params=querystring)\n",
    "            article = ([v for v in json.loads(response.text)['data']\n",
    "                        if v['story_postdate'] == news_date.strftime(\"%-m/%-d/%Y\")][0]\n",
    "                       if news_date else json.loads(response.text)['data'][0])\n",
    "            news_date = (datetime.strptime(article['story_postdate'],\n",
    "                                           '%m/%d/%Y').date()\n",
    "                         if not news_date else news_date)\n",
    "\n",
    "            htmldata = request(\"GET\", base_url + article['story_path'], headers=headers).text\n",
    "            soup = BeautifulSoup(htmldata, 'html.parser')\n",
    "            image_path = [i['src'] for i in soup.find_all('img') if i.has_attr('src')][2]\n",
    "            response = request(\"GET\", image_path, headers=headers)\n",
    "            if not path.exists(path.dirname(file_path)):\n",
    "                mkdir(path.dirname(file_path))\n",
    "            with open(file_path, 'wb') as f:\n",
    "                f.write(response.content)\n",
    "            # print('Image `{}` downloaded.'.format(file_path))\n",
    "            key['name'] = article['story_headline']\n",
    "        else:\n",
    "            key['name'] = 'No Title (loaded from cache)'\n",
    "            # print('Image `{}` read from cache.'.format(file_path))\n",
    "\n",
    "        with open(file_path, mode='rb') as f:\n",
    "            key['image'] = f.read()\n",
    "        self.insert1(key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how this has updated our entity relationships:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dj.Di(schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check if there is any data yet in our new `Headline` table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Headline()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our `Imported` table is ready to synchronize with the upstream but it is waiting for us to tell it to run the computations or populate itself. To do this, we can simply call the `populate` method on our `Headline` table. After running it, we can call populate as many times as we want after this since DataJoint will only process new entries upstream."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Headline.populate(display_progress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Teardown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Welcome to the UH workshop environment!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Workshop setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd /home/notebooks/notebook\n",
    "import datajoint as dj\n",
    "dj.config['database.password'] = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Workshop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Connecting to your data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datajoint as dj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Open connection to a database server instance i.e. Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dj.conn()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List databases you have access to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dj.list_schemas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem statement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- You are a journalist at UH covering sporting events around campus\n",
    "- There are various sports for both men and women atheletes\n",
    "- Each sporting event needs a article piece to promote cover the event\n",
    "- This article will include both a headline and a thumbnail image\n",
    "- To promote both the article + sport, we should come up with an attention grabbing flyer of the article thumbnails"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Structuring your data using a database i.e. Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = dj.Schema('{user}_uh-showcase'.format(user=dj.config['database.user']))\n",
    "schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dj.Diagram(schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@schema\n",
    "class Sport(dj.Manual):\n",
    "    definition = \"\"\"\n",
    "    sport_id        :  int auto_increment\n",
    "    ---\n",
    "    name      : varchar(30)\n",
    "    sex=\"men\" : enum(\"women\", \"men\")\n",
    "    unique index(name, sex)\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sport.insert([\n",
    "    dict(name='swim', sex='women'),\n",
    "    dict(name='soc', sex='women')\n",
    "])\n",
    "Sport.insert([\n",
    "    dict(name='track'),\n",
    "    dict(name='football')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sport()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sport & dict(sex='women')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = Sport & \"sex='men'\"\n",
    "q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q.fetch(order_by='name DESC', format='frame')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q.fetch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sport - dict(sex='men')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(Sport - dict(sex='men')).make_sql()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@schema\n",
    "class NewsArticle(dj.Manual):\n",
    "    definition = \"\"\"\n",
    "    -> Sport\n",
    "    news_id       : int\n",
    "    ---\n",
    "    date=null: date\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dj.Di(schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NewsArticle.insert([\n",
    "    # [4, 2, date(2020,3,3)],\n",
    "    [2, 2, date(2019,11,5)],\n",
    "    [1, 2, date(2020,3,11)],\n",
    "    [3, 2, date(2020,3,4)],\n",
    "])\n",
    "# NewsArticle.insert([\n",
    "#     dict(sport_id=1, news_id=1),\n",
    "#     dict(sport_id=3, news_id=1)\n",
    "# ])\n",
    "# NewsArticle.insert([\n",
    "#     [4, 1, date(2021,1,29)],\n",
    "#     [2, 1, date(2021,4,9)],\n",
    "#     [1, 1, date(2021,3,20)],\n",
    "#     [3, 1, date(2021,4,8)],\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NewsArticle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sport * NewsArticle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from requests import request\n",
    "import json\n",
    "from os import path, mkdir\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@schema\n",
    "class Headline(dj.Imported):\n",
    "    definition = \"\"\"\n",
    "    -> NewsArticle\n",
    "    ---\n",
    "    name : varchar(200)\n",
    "    image: longblob\n",
    "    \"\"\"\n",
    "    def make(self, key):    \n",
    "        sport_name, sport_sex = (Sport & key).fetch1('name', 'sex')\n",
    "        news_date = (NewsArticle & key).fetch1('date')\n",
    "        file_path = 'cached/{}_{}_{}.jpg'.format(sport_name, sport_sex, news_date)\n",
    "\n",
    "        if not path.exists(file_path):\n",
    "            base_url = \"https://uhcougars.com\"\n",
    "            headers = {\n",
    "                'User-Agent': \"DataJoint\"\n",
    "            }\n",
    "            querystring = {\n",
    "                \"index\":\"1\",\n",
    "                \"page_size\":\"200\",\n",
    "                \"sport\": sport_name if sport_sex != 'women' else sport_sex[0] + sport_name,\n",
    "                \"season\":\"0\"\n",
    "            }\n",
    "            response = request(\"GET\", base_url + \"/services/archives.ashx/stories\",\n",
    "                               headers=headers, params=querystring)\n",
    "            article = ([v for v in json.loads(response.text)['data']\n",
    "                        if v['story_postdate'] == news_date.strftime(\"%-m/%-d/%Y\")][0]\n",
    "                       if news_date else json.loads(response.text)['data'][0])\n",
    "            news_date = (datetime.strptime(article['story_postdate'],\n",
    "                                           '%m/%d/%Y').date()\n",
    "                         if not news_date else news_date)\n",
    "\n",
    "            htmldata = request(\"GET\", base_url + article['story_path'], headers=headers).text\n",
    "            soup = BeautifulSoup(htmldata, 'html.parser')\n",
    "#             print([i['src'] for i in soup.find_all('img') if i.has_attr('src')])\n",
    "            image_path = [i['src'] for i in soup.find_all('img') if i.has_attr('src')][2]\n",
    "            response = request(\"GET\", image_path, headers=headers)\n",
    "            if not path.exists(path.dirname(file_path)):\n",
    "                mkdir(path.dirname(file_path))\n",
    "            with open(file_path, 'wb') as f:\n",
    "                f.write(response.content)\n",
    "            print('Image `{}` downloaded.'.format(file_path))\n",
    "            key['name'] = article['story_headline']\n",
    "        else:\n",
    "            key['name'] = 'No Title (loaded from cache)'\n",
    "            print('Image `{}` read from cache.'.format(file_path))\n",
    "\n",
    "        with open(file_path, mode='rb') as f:\n",
    "            key['image'] = f.read()\n",
    "        self.insert1(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dj.Di(schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Headline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Headline.populate(display_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_original = Headline()\n",
    "q_original = Headline & dict(sport_id=1, news_id=2)\n",
    "q_original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_original = q_original.fetch1('image')\n",
    "image_original = Image.open(BytesIO(image_original))\n",
    "fig, axarr = plt.subplots(1,1,figsize=(15,15))\n",
    "axarr.imshow(image_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@schema\n",
    "class PaintingStyle(dj.Lookup):\n",
    "    definition = \"\"\"\n",
    "    style_name      : varchar(30)\n",
    "    \"\"\"\n",
    "    contents = [\n",
    "        ['udnie']\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dj.Di(schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PaintingStyle.insert([\n",
    "    dict(style_name='mosaic')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PaintingStyle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import imutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@schema\n",
    "class Flyer(dj.Computed):\n",
    "    definition = \"\"\"\n",
    "    -> Headline\n",
    "    -> PaintingStyle\n",
    "    ---\n",
    "    image: longblob\n",
    "    \"\"\"\n",
    "    def make(self, key):\n",
    "        style_path = 'models/' + key['style_name'] + '.t7'\n",
    "        image = (Headline & key).fetch1('image')\n",
    "        \n",
    "        net = cv2.dnn.readNetFromTorch(style_path)\n",
    "        image = np.frombuffer(image, np.uint8)\n",
    "        image = cv2.imdecode(image, cv2.IMREAD_COLOR)\n",
    "#         image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "        image = imutils.resize(image, width=600)\n",
    "        (h, w) = image.shape[:2]\n",
    "\n",
    "        # construct a blob from the image, set the input, and then perform a\n",
    "        # forward pass of the network\n",
    "        blob = cv2.dnn.blobFromImage(image, 1.0, (w, h),\n",
    "            (103.939, 116.779, 123.680), swapRB=False, crop=False)\n",
    "        net.setInput(blob)\n",
    "        output = net.forward()\n",
    "\n",
    "        # reshape the output tensor, add back in the mean subtraction, and\n",
    "        # then swap the channel ordering\n",
    "        output = output.reshape((3, output.shape[2], output.shape[3]))\n",
    "        output[0] += 103.939\n",
    "        output[1] += 116.779\n",
    "        output[2] += 123.680\n",
    "        output = output.transpose(1, 2, 0)\n",
    "        output = np.clip(output, 0, 255)\n",
    "        output= output.astype('uint8')\n",
    "        \n",
    "        print('sport_id: {sport_id}, news_id: {news_id}, style_name: {style_name}'.format(**key))\n",
    "        \n",
    "        key['image'] = cv2.imencode('.jpg', output)[1].tobytes()\n",
    "        self.insert1(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dj.Di(schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Flyer.populate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_styled = Flyer()\n",
    "# q_styled = Flyer & dict(sport_id=1, news_id=2, style_name='udnie')\n",
    "q_styled = Flyer & dict(sport_id=1, news_id=2, style_name='mosaic')\n",
    "q_styled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_styled = q_styled.fetch1('image')\n",
    "image_styled = Image.open(BytesIO(image_styled))\n",
    "\n",
    "fig, axarr = plt.subplots(1,2,figsize=(15,15))\n",
    "axarr[0].imshow(image_original)\n",
    "axarr[1].imshow(image_styled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_styled.save(\"./image_styled.jpg\", 'jpeg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean up and remove generated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema.drop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "shutil.rmtree('cached')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.unlink(\"./image_styled.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
