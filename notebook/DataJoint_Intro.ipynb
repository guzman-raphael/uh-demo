{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Welcome!"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We appreciate you attending our DataJoint workshop. Let's learn how easy it is to create a DataJoint computational pipeline from scratch."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Setup"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Please run the below but feel free to disregard it as it is just some environment specific setup configuration."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "cd /home/notebooks/notebook"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import datajoint as dj\n",
    "dj.config['database.password'] = None"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from datetime import date, datetime\n",
    "from requests import request\n",
    "import json\n",
    "from os import path, mkdir\n",
    "from bs4 import BeautifulSoup\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import imutils"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Workshop"
   ],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Problem Statement"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- You are a journalist at UH covering sporting events around campus\n",
    "- There are various sports for both men and women atheletes\n",
    "- Each sporting event needs an article piece created on a specific date to promote and cover the event\n",
    "- An article should include both a headline and a thumbnail image\n",
    "- To promote both the article + sport, we should come up with an *attention-grabbing* flyer based on the article's thumbnail"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Getting Connected"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's start by importing `datajoint`."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import datajoint as dj"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Next, let's open a connection to a database server instance or sometimes referred to as a pipeline. This step is not necessary but useful in debugging or simply verifying you have access."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "dj.conn()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can list the databases you have access to by running:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "dj.list_schemas()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Creating a Schema"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now let's create a database or sometimes referred to as a schema (in MySQL). This will be the primary namespace where we will  create our pipeline. Note that we only needed to use your username as a prefix since that is the policy for the free space available to CodeBook users."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "schema = dj.Schema('{user}_uh-showcase'.format(user=dj.config['database.user']))\n",
    "schema"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Designing your Pipeline"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "From the description of the problem, we can make the following assumptions:\n",
    "- A `Sport` has an attribute that determines whether it is for `men` or `women`\n",
    "- `Sport:NewsArticle` should have a `1:M` relationship\n",
    "- A `NewsArticle` has an attribute to specify when it was created\n",
    "- A `NewsArticle` has a `1:1` relationship both for its headline and thumbnail"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's start with the most basic of DataJoint table types: the `Manual` table."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "@schema\n",
    "class Sport(dj.Manual):\n",
    "    definition = \"\"\"\n",
    "    sport_id  : int auto_increment\n",
    "    ---\n",
    "    name      : varchar(30)\n",
    "    sex=\"men\" : enum(\"women\", \"men\")\n",
    "    unique index(name, sex)\n",
    "    \"\"\""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "@schema\n",
    "class NewsArticle(dj.Manual):\n",
    "    definition = \"\"\"\n",
    "    -> Sport\n",
    "    news_id   : int\n",
    "    ---\n",
    "    date=null : date\n",
    "    \"\"\""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Notice how the table names were chosen. Typically in DataJoint, we try to be consistent with our naming here representing each record in the table as an entity or object."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "To help visualize our pipeline, we can use the `dj.Diagram` function or `dj.Di` for short."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "dj.Di(schema)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Inserting Records"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's initialize some sports."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "Sport.insert([\n",
    "    dict(name='swim', sex='women'),\n",
    "    dict(name='soc', sex='women')\n",
    "])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's also leverage the default value feature."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "Sport.insert([\n",
    "    dict(name='track'),\n",
    "    dict(name='football')\n",
    "])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "To confirm our inserts, we can preview the table's contents by running the following:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "Sport()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now let's add some entries into for our news articles that correspond to actual articles from UH's athletics site: https://uhcougars.com/."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "NewsArticle.insert([\n",
    "    [2, 1, date(2019,11,5)],\n",
    "    [1, 1, date(2020,3,11)],\n",
    "    [3, 1, date(2020,3,4)],\n",
    "])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "NewsArticle()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Querying"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Suppose now that we wanted to perform some query to our pipeline to extract data from it. The following are a few examples showing how easy it is to use the DataJoint syntax to achieve this."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Query1: `women` sports"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "Sport & dict(sex='women')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Query2: `men` sports"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "q = Sport & \"sex='men'\"\n",
    "q"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Query3: Exclude any `men` sports"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "q = Sport - dict(sex='men')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "`q` here is actually just a query expression and unevaluated. Think of `q` as a query builder. The only reason why the queries were displaying values before is because we have been utilizing Jupyter's preview feature (which limits the results). It is important to understand that queries aren't expected to actually run until we can `fetch` on them (more on this later)."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "isinstance(q, dj.expression.QueryExpression)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here we can manually ask Jupyter to preview the query for us."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "q"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "A great debugging tool as well is `make_sql` which allows us to see the assembled SQL query."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "q.make_sql()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Query4: Articles for `women`'s sports"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "NewsArticle()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "q = Sport * NewsArticle & \"sex = 'women'\"\n",
    "q"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "To properly run and fetch your query, you'd call `fetch` on your query expression like so:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "q.fetch()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "q.fetch(as_dict=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "q.fetch('name', 'sex', as_dict=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Computation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "In DataJoint, computation is a native part of interacting with your data. Let's see how to leverage this within our pipeline."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "First, some important principles:\n",
    "- There are 2 different kinds of computed tables in DataJoint: `Imported` and `Computed`.\n",
    "- They operate essentially the same way but we differentiate them purely on convention and how they are used.\n",
    "- `Imported` tables signal that there is external data being introduced into the pipeline.\n",
    "- `Computed` tables signal that there is new data being introduced but sourced from within the pipeline itself or sometimes referred to as upstream."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "So we can include this in our design by creating an `Imported` table that runs a web scraping computation to fetch the headline and thumbnail for the articles. Then, we can create a `Computed` table that runs a computation to modify our thumbnail to make it more interesting."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's start first with our `Imported` table. We can make the following assumptions:\n",
    "- The `Headline` table will store both the headline and the thumbnail for an article's given date.\n",
    "- A record in the `Headline` table should correspond to a single news article i.e. `1:1` relationship.\n",
    "- Since we will be working with an image, it is best to store the image as a BLOB i.e. large binary object. `longblob` is a good data type for this."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "@schema\n",
    "class Headline(dj.Imported):\n",
    "    definition = \"\"\"\n",
    "    -> NewsArticle\n",
    "    ---\n",
    "    name : varchar(200)\n",
    "    image: longblob\n",
    "    \"\"\"\n",
    "\n",
    "    def make(self, key):    \n",
    "        sport_name, sport_sex = (Sport & key).fetch1('name', 'sex')\n",
    "        news_date = (NewsArticle & key).fetch1('date')\n",
    "        file_path = 'cached/{}_{}_{}.jpg'.format(sport_name, sport_sex, news_date)\n",
    "\n",
    "        if not path.exists(file_path):\n",
    "            base_url = \"https://uhcougars.com\"\n",
    "            headers = {\n",
    "                'User-Agent': \"DataJoint\"\n",
    "            }\n",
    "            querystring = {\n",
    "                \"index\":\"1\",\n",
    "                \"page_size\":\"200\",\n",
    "                \"sport\": sport_name if sport_sex != 'women' else sport_sex[0] + sport_name,\n",
    "                \"season\":\"0\"\n",
    "            }\n",
    "            response = request(\"GET\", base_url + \"/services/archives.ashx/stories\",\n",
    "                               headers=headers, params=querystring)\n",
    "            article = ([v for v in json.loads(response.text)['data']\n",
    "                        if v['story_postdate'] == news_date.strftime(\"%-m/%-d/%Y\")][0]\n",
    "                       if news_date else json.loads(response.text)['data'][0])\n",
    "            news_date = (datetime.strptime(article['story_postdate'],\n",
    "                                           '%m/%d/%Y').date()\n",
    "                         if not news_date else news_date)\n",
    "\n",
    "            htmldata = request(\"GET\", base_url + article['story_path'], headers=headers).text\n",
    "            soup = BeautifulSoup(htmldata, 'html.parser')\n",
    "            image_path = [i['src'] for i in soup.find_all('img') if i.has_attr('src')][2]\n",
    "            response = request(\"GET\", image_path, headers=headers)\n",
    "            if not path.exists(path.dirname(file_path)):\n",
    "                mkdir(path.dirname(file_path))\n",
    "            with open(file_path, 'wb') as f:\n",
    "                f.write(response.content)\n",
    "            # print('Image `{}` downloaded.'.format(file_path))\n",
    "            key['name'] = article['story_headline']\n",
    "        else:\n",
    "            key['name'] = 'No Title (loaded from cache)'\n",
    "            # print('Image `{}` read from cache.'.format(file_path))\n",
    "\n",
    "        with open(file_path, mode='rb') as f:\n",
    "            key['image'] = f.read()\n",
    "        self.insert1(key)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's see how this has updated our entity relationships:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "dj.Di(schema)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's check if there is any data yet in our new `Headline` table."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "Headline()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Our `Imported` table is ready to synchronize with the upstream but it is waiting for us to tell it to run the computations i.e. populate itself. To do this, we can simply call the `populate` method on our `Headline` table. After running it, we can call populate as many additional times as we want since DataJoint will only process new entries from upstream."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "Headline.populate(display_progress=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now let's see the new headline entries."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "Headline()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Notice that the BLOB data is not actually rendered but simply labeled in this preview state. To actually display an individual image, we'll need to:\n",
    "- create a proper query\n",
    "- fetch the query\n",
    "- render it properly\n",
    "\n",
    "Let's go for it!"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "restriction = dict(sport_id=1, news_id=1)\n",
    "q_original = Headline & restriction"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "image_original = q_original.fetch1('image')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "image_original = Image.open(BytesIO(image_original))\n",
    "fig, axarr = plt.subplots(1, 1, figsize=(15,15))\n",
    "axarr.imshow(image_original)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Great! Now we just need to add our `Computed` table to spruce up our thumbnail for our promotional flyer."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "How about we make it interesting by using a pre-trained machine learning model that will apply a style transfer of a famous painting to the image?\n",
    "\n",
    "Since we have them already available in this environment under the `models` directory, we can create a `Flyer` table that will process an image based on an input for the painting style."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "But first, let's create a `Lookup` table. A `Lookup` table is very similar to a `Manual` table with the exception that it allows you to initialize it with some standard values (you can always insert more if you like after). It is a great companion to a `Computed` table since we can use it to manage variables for computation."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "@schema\n",
    "class PaintingStyle(dj.Lookup):\n",
    "    definition = \"\"\"\n",
    "    style_name      : varchar(30)\n",
    "    \"\"\"\n",
    "    contents = [\n",
    "        dict(style_name='udnie'),\n",
    "        dict(style_name='mosaic'),\n",
    "    ]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's display it's contents for good measure."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "PaintingStyle()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "And finally, let's add our last table: `Flyer`. This should perform our style transfer on new records upstream from this point."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "@schema\n",
    "class Flyer(dj.Computed):\n",
    "    definition = \"\"\"\n",
    "    -> Headline\n",
    "    -> PaintingStyle\n",
    "    ---\n",
    "    image: longblob\n",
    "    \"\"\"\n",
    "    def make(self, key):\n",
    "        style_path = 'models/' + key['style_name'] + '.t7'\n",
    "        image = (Headline & key).fetch1('image')\n",
    "        \n",
    "        net = cv2.dnn.readNetFromTorch(style_path)\n",
    "        image = np.frombuffer(image, np.uint8)\n",
    "        image = cv2.imdecode(image, cv2.IMREAD_COLOR)\n",
    "#         image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "        image = imutils.resize(image, width=600)\n",
    "        (h, w) = image.shape[:2]\n",
    "\n",
    "        # construct a blob from the image, set the input, and then perform a\n",
    "        # forward pass of the network\n",
    "        blob = cv2.dnn.blobFromImage(image, 1.0, (w, h),\n",
    "            (103.939, 116.779, 123.680), swapRB=False, crop=False)\n",
    "        net.setInput(blob)\n",
    "        output = net.forward()\n",
    "\n",
    "        # reshape the output tensor, add back in the mean subtraction, and\n",
    "        # then swap the channel ordering\n",
    "        output = output.reshape((3, output.shape[2], output.shape[3]))\n",
    "        output[0] += 103.939\n",
    "        output[1] += 116.779\n",
    "        output[2] += 123.680\n",
    "        output = output.transpose(1, 2, 0)\n",
    "        output = np.clip(output, 0, 255)\n",
    "        output= output.astype('uint8')\n",
    "        \n",
    "        # print('sport_id: {sport_id}, news_id: {news_id}, style_name: {style_name}'.format(**key))\n",
    "        \n",
    "        key['image'] = cv2.imencode('.jpg', output)[1].tobytes()\n",
    "        self.insert1(key)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's see how our relationships are shaping up so far."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "dj.Di(schema)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now let's wrap it up by generating some cool flyers."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "Flyer.populate(display_progress=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Just one final touch to see the results of our hard work."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "q_styled = Flyer & restriction & dict(style_name='mosaic')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "image_styled = q_styled.fetch1('image')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "image_styled = Image.open(BytesIO(image_styled))\n",
    "\n",
    "fig, axarr = plt.subplots(1,2,figsize=(15,15))\n",
    "axarr[0].imshow(image_original)\n",
    "axarr[1].imshow(image_styled)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Teardown"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import shutil\n",
    "shutil.rmtree('cached')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "schema.drop()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}